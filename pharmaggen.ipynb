{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8Z3sMcIwgwj0cuvJvX/rp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChandanaDCgithub/Gen-ai/blob/master/pharmaggen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYxed1Z0ft-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a85d323-0baf-4847-8ff8-3f6193900675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m630.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.3.2)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed torch-2.1.2+cu118 torchaudio-2.1.2+cu118 torchvision-0.16.2+cu118 triton-2.1.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.2+cu118)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, accelerate, gradio\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.5.2\n",
            "    Uninstalling accelerate-1.5.2:\n",
            "      Successfully uninstalled accelerate-1.5.2\n",
            "Successfully installed accelerate-1.6.0 aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -U transformers accelerate sentencepiece gradio google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvMf5hCwY3go",
        "outputId": "caa86945-e67b-4ae6-aafd-bef1c9e9fa6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=4d0b2d49468cad334633fd0faf016a151a2d8fc90d34c8c63b12b367bc456306\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from fpdf import FPDF  # For PDF generation\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab environment\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Google Colab environment\")\n",
        "\n",
        "# Function for direct PDF download in Colab\n",
        "def download_pdf_in_colab(pdf_path):\n",
        "    if IN_COLAB and pdf_path and os.path.exists(pdf_path):\n",
        "        files.download(pdf_path)\n",
        "        return \"PDF downloaded in Colab\"\n",
        "    return pdf_path\n",
        "\n",
        "# --- Configuration ---\n",
        "# Gemini API Model\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash-latest\"  # Or \"gemini-1.5-pro-latest\"\n",
        "\n",
        "# Language mapping for translation\n",
        "LANG_CODES = {\n",
        "    \"English\": \"en\", \"Arabic\": \"ar\", \"German\": \"de\", \"Spanish\": \"es\", \"French\": \"fr\",\n",
        "    \"Hindi\": \"hi\", \"Italian\": \"it\", \"Japanese\": \"ja\", \"Korean\": \"ko\", \"Portuguese\": \"pt\",\n",
        "    \"Russian\": \"ru\", \"Chinese\": \"zh\", \"Bengali\": \"bn\", \"Tamil\": \"ta\", \"Telugu\": \"te\",\n",
        "    \"Thai\": \"th\", \"Ukrainian\": \"uk\", \"Turkish\": \"tr\", \"Vietnamese\": \"vi\", \"Kannada\": \"kn\"\n",
        "}\n",
        "\n",
        "# --- API Initialization ---\n",
        "# Hardcoded API key - replace with your actual key\n",
        "API_KEY = \"AIzaSyCWrNK1R7CWrJ2ju6ZQG2nAyT30fzB-cw8\"\n",
        "\n",
        "gemini_client = None\n",
        "try:\n",
        "    genai.configure(api_key=API_KEY)\n",
        "    gemini_client = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
        "    print(f\"Gemini API client initialized with model: {GEMINI_MODEL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Gemini model: {e}\")\n",
        "    print(\"Please check if the model name is correct and your API key is valid.\")\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def gemini_translate(text, src_lang_code, tgt_lang_code, temp=0.1):\n",
        "    \"\"\"Translates text using Gemini.\"\"\"\n",
        "    if gemini_client is None:\n",
        "        print(\"Gemini client not available for translation.\")\n",
        "        return text  # Return original text if Gemini client fails\n",
        "\n",
        "    if not text or text.strip() == \"\":\n",
        "        return \"\"\n",
        "\n",
        "    # Handle cases where lang code might be None\n",
        "    effective_src_lang_code = src_lang_code if src_lang_code in LANG_CODES.values() else \"auto\"\n",
        "    effective_tgt_lang_code = tgt_lang_code if tgt_lang_code in LANG_CODES.values() else \"en\"\n",
        "\n",
        "    if effective_src_lang_code != \"auto\" and effective_src_lang_code == effective_tgt_lang_code:\n",
        "        return text  # Skip translation if source equals target\n",
        "\n",
        "    # Get language name from code\n",
        "    tgt_lang_name = next((name for name, code in LANG_CODES.items() if code == effective_tgt_lang_code), effective_tgt_lang_code)\n",
        "    prompt = f\"Translate the following text to {tgt_lang_name}:\\n\\n{text}\"\n",
        "\n",
        "    if effective_src_lang_code != \"auto\":\n",
        "        src_lang_name = next((name for name, code in LANG_CODES.items() if code == effective_src_lang_code), effective_src_lang_code)\n",
        "        prompt = f\"Translate the following text from {src_lang_name} to {tgt_lang_name}:\\n\\n{text}\"\n",
        "\n",
        "    try:\n",
        "        response = gemini_client.generate_content(prompt, generation_config=genai.GenerationConfig(temperature=temp))\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Translation error: {e}\")\n",
        "        return text\n",
        "\n",
        "def get_gemini_response(prompt_text, chat_history=None, temp=0.7):\n",
        "    \"\"\"Gets a response from the Gemini API.\"\"\"\n",
        "    if gemini_client is None:\n",
        "        return \"Error: Gemini API not available. Cannot provide medical information.\"\n",
        "\n",
        "    try:\n",
        "        # Format chat history for Gemini\n",
        "        formatted_history = []\n",
        "        if chat_history:\n",
        "            for turn in chat_history:\n",
        "                if isinstance(turn, dict) and \"role\" in turn and \"parts\" in turn:\n",
        "                    formatted_history.append({\"role\": turn[\"role\"], \"parts\": [{\"text\": turn[\"parts\"][0][\"text\"]}]})\n",
        "\n",
        "        if formatted_history:\n",
        "            chat_session = gemini_client.start_chat(history=formatted_history)\n",
        "            response = chat_session.send_message(prompt_text)\n",
        "        else:\n",
        "            response = gemini_client.generate_content(prompt_text, generation_config=genai.GenerationConfig(temperature=temp))\n",
        "\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API error: {e}\")\n",
        "        error_detail = str(e).lower()\n",
        "        if \"401\" in error_detail or \"unauthorized\" in error_detail:\n",
        "            return f\"Error: Unauthorized. Check your API key. {e}\"\n",
        "        if \"429\" in error_detail or \"quota\" in error_detail:\n",
        "            return f\"Error: Rate limit exceeded. Try again later. {e}\"\n",
        "        return f\"Error communicating with Gemini API: {e}\"\n",
        "\n",
        "class PDFReport(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'PharmaGPT Medical Report', 0, 1, 'C')\n",
        "        self.ln(5)\n",
        "\n",
        "    def footer(self):\n",
        "        self.set_y(-15)\n",
        "        self.set_font('Arial', 'I', 8)\n",
        "        self.cell(0, 10, f'Page {self.page_no()}/{{nb}}', 0, 0, 'C')\n",
        "        self.ln(5)\n",
        "        self.set_font('Arial', 'I', 7)\n",
        "        self.cell(0, 10, 'Disclaimer: This is an AI-generated report for conceptual purposes only.', 0, 0, 'C')\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, self._sanitize_text(title), 0, 1, 'L')\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 10)\n",
        "        if not isinstance(body, str):\n",
        "            body = str(body)\n",
        "        self.multi_cell(0, 5, self._sanitize_text(body))\n",
        "        self.ln(5)\n",
        "\n",
        "    def _sanitize_text(self, text):\n",
        "        # Replace non-Latin characters with their closest Latin equivalents or descriptions\n",
        "        return text.encode('latin-1', 'replace').decode('latin-1')\n",
        "\n",
        "def generate_pdf_report(chat_state):\n",
        "    \"\"\"Generates a simplified PDF report from the collected data in the user's preferred language.\"\"\"\n",
        "    print(\"Generating PDF report...\")\n",
        "    state_data = chat_state.copy()\n",
        "\n",
        "    # Get user's language\n",
        "    user_lang_code = state_data.get(\"lang_code\", \"en\")\n",
        "    user_language = state_data.get(\"language\", \"English\")\n",
        "\n",
        "    # Get data from chat state\n",
        "    symptoms_user_lang = state_data.get(\"symptoms_user_lang\", \"None reported\")\n",
        "    allergies_user_lang = state_data.get(\"allergies_user_lang\", \"None reported\")\n",
        "\n",
        "    # Extract sections from the full response if available\n",
        "    drug_concept_full_en = state_data.get(\"drug_concept_full_en\", \"\")\n",
        "\n",
        "    if drug_concept_full_en:\n",
        "        # Extract sections using regex\n",
        "        diagnosis_match = re.search(r\"Diagnosis:(.*?)(?:Proposed New Drug:|Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                drug_concept_full_en, re.DOTALL | re.IGNORECASE)\n",
        "        drug_concept_match = re.search(r\"Proposed New Drug:(.*?)(?:Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                    drug_concept_full_en, re.DOTALL | re.IGNORECASE)\n",
        "        dosage_match = re.search(r\"Hypothetical Dosage/Instructions:(.*?)(?:Allergy/Safety Note:|$)\",\n",
        "                                drug_concept_full_en, re.DOTALL | re.IGNORECASE)\n",
        "        safety_match = re.search(r\"Allergy/Safety Note:(.*)\",\n",
        "                                drug_concept_full_en, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "        diagnosis = diagnosis_match.group(1).strip() if diagnosis_match else \"Not found\"\n",
        "        drug_concept = drug_concept_match.group(1).strip() if drug_concept_match else \"Not found\"\n",
        "        dosage = dosage_match.group(1).strip() if dosage_match else \"Not found\"\n",
        "        safety = safety_match.group(1).strip() if safety_match else \"Not found\"\n",
        "\n",
        "        # Create simplified versions of each section\n",
        "        simplified_diagnosis_prompt = \"Simplify this medical diagnosis into 2-3 short bullet points: \" + diagnosis\n",
        "        simplified_drug_prompt = \"Simplify this drug concept into 2-3 short bullet points about what it is and how it works: \" + drug_concept\n",
        "        simplified_dosage_prompt = \"Simplify this dosage information into 2-3 short bullet points about dosage amount, frequency, and how to take it: \" + dosage\n",
        "        simplified_safety_prompt = \"Simplify this safety information into 2-3 short bullet points about allergies and side effects: \" + safety\n",
        "\n",
        "        simplified_diagnosis_en = get_gemini_response(simplified_diagnosis_prompt)\n",
        "        simplified_drug_en = get_gemini_response(simplified_drug_prompt)\n",
        "        simplified_dosage_en = get_gemini_response(simplified_dosage_prompt)\n",
        "        simplified_safety_en = get_gemini_response(simplified_safety_prompt)\n",
        "\n",
        "        # Translate simplified sections to user's language\n",
        "        diagnosis_translated = gemini_translate(simplified_diagnosis_en, \"en\", user_lang_code)\n",
        "        drug_concept_translated = gemini_translate(simplified_drug_en, \"en\", user_lang_code)\n",
        "        dosage_translated = gemini_translate(simplified_dosage_en, \"en\", user_lang_code)\n",
        "        safety_translated = gemini_translate(simplified_safety_en, \"en\", user_lang_code)\n",
        "\n",
        "        # Translate section titles\n",
        "        report_title = gemini_translate(\"Medical Report\", \"en\", user_lang_code)\n",
        "        symptoms_title = gemini_translate(\"Symptoms\", \"en\", user_lang_code)\n",
        "        allergies_title = gemini_translate(\"Allergies\", \"en\", user_lang_code)\n",
        "        diagnosis_title = gemini_translate(\"Diagnosis\", \"en\", user_lang_code)\n",
        "        drug_title = gemini_translate(\"Medicine\", \"en\", user_lang_code)\n",
        "        dosage_title = gemini_translate(\"Dosage\", \"en\", user_lang_code)\n",
        "        safety_title = gemini_translate(\"Safety Notes\", \"en\", user_lang_code)\n",
        "        disclaimer_title = gemini_translate(\"Disclaimer\", \"en\", user_lang_code)\n",
        "        disclaimer_text = gemini_translate(\"This is an AI-generated report for conceptual purposes only. Consult a medical professional.\", \"en\", user_lang_code)\n",
        "    else:\n",
        "        # If no diagnosis was generated yet\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Create PDF\n",
        "        pdf = PDFReport()\n",
        "        pdf.alias_nb_pages()\n",
        "        pdf.add_page()\n",
        "\n",
        "        # Add title in user's language\n",
        "        pdf.set_font('Arial', 'B', 16)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(report_title), 0, 1, 'C')\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Add language indicator\n",
        "        pdf.set_font('Arial', 'I', 10)\n",
        "        pdf.cell(0, 10, f\"Report in {user_language}\", 0, 1, 'C')\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Patient Information - Simplified\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, f\"{pdf._sanitize_text(symptoms_title)}:\", 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(symptoms_user_lang))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, f\"{pdf._sanitize_text(allergies_title)}:\", 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(allergies_user_lang))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Diagnosis - Simplified\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(diagnosis_title), 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(diagnosis_translated))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Drug - Simplified\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(drug_title), 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(drug_concept_translated))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Dosage - Simplified\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(dosage_title), 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(dosage_translated))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Safety - Simplified\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(safety_title), 0, 1, 'L')\n",
        "        pdf.set_font('Arial', '', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(safety_translated))\n",
        "        pdf.ln(5)\n",
        "\n",
        "        # Disclaimer\n",
        "        pdf.set_font('Arial', 'B', 12)\n",
        "        pdf.cell(0, 10, pdf._sanitize_text(disclaimer_title), 0, 1, 'L')\n",
        "        pdf.set_font('Arial', 'I', 10)\n",
        "        pdf.multi_cell(0, 5, pdf._sanitize_text(disclaimer_text))\n",
        "\n",
        "        # Save PDF\n",
        "        pdf_output_path = \"./pharma_gpt_report.pdf\"\n",
        "        pdf.output(pdf_output_path)\n",
        "        print(f\"PDF report saved to {pdf_output_path}\")\n",
        "        return pdf_output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Chat Stages ---\n",
        "CHAT_STAGE_ASK_LANGUAGE = \"ask_language\"\n",
        "CHAT_STAGE_ASK_SYMPTOMS = \"ask_symptoms\"\n",
        "CHAT_STAGE_ASK_ALLERGIES = \"ask_allergies\"\n",
        "CHAT_STAGE_GENERATE_RESPONSE = \"generate_response\"\n",
        "CHAT_STAGE_GENERAL_QNA = \"general_qna\"\n",
        "\n",
        "# Initialize chat state\n",
        "def initialize_chat_state():\n",
        "    return {\n",
        "        \"stage\": CHAT_STAGE_ASK_LANGUAGE,\n",
        "        \"language\": None,\n",
        "        \"lang_code\": None,\n",
        "        \"symptoms_user_lang\": None,\n",
        "        \"symptoms_en\": None,\n",
        "        \"allergies_user_lang\": None,\n",
        "        \"allergies_en\": None,\n",
        "        \"diagnosis_en\": None,\n",
        "        \"drug_concept_full_en\": None,\n",
        "        \"gemini_chat_history_manual\": []\n",
        "    }\n",
        "\n",
        "# Process chat messages\n",
        "def process_chat(message, history, state):\n",
        "    \"\"\"Process user messages and generate responses.\"\"\"\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # Add user message to history\n",
        "    history.append([message, \"\"])\n",
        "\n",
        "    try:\n",
        "        current_stage = state[\"stage\"]\n",
        "        user_lang_code = state.get(\"lang_code\", \"en\")\n",
        "\n",
        "        # Translate user message to English if needed\n",
        "        user_message_en = message\n",
        "        if user_lang_code != \"en\" and user_lang_code is not None and message.strip():\n",
        "            user_message_en = gemini_translate(message, user_lang_code, 'en')\n",
        "\n",
        "        bot_response_en = \"\"\n",
        "        bot_response_user_lang = \"\"\n",
        "\n",
        "        # Initialize summary outputs\n",
        "        english_summary = \"Report summary will appear here after diagnosis.\"\n",
        "        translated_summary = \"Translated report summary will appear here.\"\n",
        "\n",
        "        # Preserve previous summary if available\n",
        "        if state.get(\"drug_concept_full_en\"):\n",
        "            full_response = state[\"drug_concept_full_en\"]\n",
        "\n",
        "            # Extract sections using regex\n",
        "            diagnosis_match = re.search(r\"Diagnosis:(.*?)(?:Proposed New Drug:|Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                      full_response, re.DOTALL | re.IGNORECASE)\n",
        "            drug_match = re.search(r\"Proposed New Drug:(.*?)(?:Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                  full_response, re.DOTALL | re.IGNORECASE)\n",
        "            dosage_match = re.search(r\"Hypothetical Dosage/Instructions:(.*?)(?:Allergy/Safety Note:|$)\",\n",
        "                                    full_response, re.DOTALL | re.IGNORECASE)\n",
        "            safety_match = re.search(r\"Allergy/Safety Note:(.*)\",\n",
        "                                    full_response, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "            diagnosis = diagnosis_match.group(1).strip() if diagnosis_match else \"Not found\"\n",
        "            drug_concept = drug_match.group(1).strip() if drug_match else \"Not found\"\n",
        "            dosage = dosage_match.group(1).strip() if dosage_match else \"Not found\"\n",
        "            safety = safety_match.group(1).strip() if safety_match else \"Not found\"\n",
        "\n",
        "            # Create English summary\n",
        "            english_summary = f\"*Symptoms:* {state.get('symptoms_en', 'N/A')}\\n\\n\"\n",
        "            english_summary += f\"*Allergies:* {state.get('allergies_en', 'N/A')}\\n\\n\"\n",
        "            english_summary += f\"*Diagnosis:* {diagnosis}\\n\\n\"\n",
        "            english_summary += f\"*Drug Concept:* {drug_concept}\\n\\n\"\n",
        "            english_summary += f\"*Dosage:* {dosage}\\n\\n\"\n",
        "            english_summary += f\"*Safety:* {safety}\\n\\n\"\n",
        "\n",
        "            # Create translated summary\n",
        "            translated_diagnosis = gemini_translate(diagnosis, \"en\", user_lang_code)\n",
        "            translated_drug = gemini_translate(drug_concept, \"en\", user_lang_code)\n",
        "            translated_dosage = gemini_translate(dosage, \"en\", user_lang_code)\n",
        "            translated_safety = gemini_translate(safety, \"en\", user_lang_code)\n",
        "\n",
        "            translated_summary = f\"{gemini_translate('Symptoms', 'en', user_lang_code)}:** {state.get('symptoms_user_lang', 'N/A')}\\n\\n\"\n",
        "            translated_summary += f\"{gemini_translate('Allergies', 'en', user_lang_code)}:** {state.get('allergies_user_lang', 'N/A')}\\n\\n\"\n",
        "            translated_summary += f\"{gemini_translate('Diagnosis', 'en', user_lang_code)}:** {translated_diagnosis}\\n\\n\"\n",
        "            translated_summary += f\"{gemini_translate('Drug Concept', 'en', user_lang_code)}:** {translated_drug}\\n\\n\"\n",
        "            translated_summary += f\"{gemini_translate('Dosage', 'en', user_lang_code)}:** {translated_dosage}\\n\\n\"\n",
        "            translated_summary += f\"{gemini_translate('Safety', 'en', user_lang_code)}:** {translated_safety}\\n\\n\"\n",
        "\n",
        "        # Process based on current stage\n",
        "        if current_stage == CHAT_STAGE_ASK_LANGUAGE:\n",
        "            selected_language = message.strip().title()\n",
        "\n",
        "            if selected_language in LANG_CODES:\n",
        "                state[\"language\"] = selected_language\n",
        "                state[\"lang_code\"] = LANG_CODES[selected_language]\n",
        "                state[\"stage\"] = CHAT_STAGE_ASK_SYMPTOMS\n",
        "                user_lang_code = state[\"lang_code\"]\n",
        "\n",
        "                # First create the English version for our records\n",
        "                welcome_message_en = f\"Thank you. Your selected language is {selected_language}.\"\n",
        "                next_prompt_en = \"Please describe your symptoms.\"\n",
        "                bot_response_en = f\"{welcome_message_en}\\n\\n{next_prompt_en}\"\n",
        "\n",
        "                # Then translate to user's language\n",
        "                welcome_message = gemini_translate(welcome_message_en, \"en\", user_lang_code)\n",
        "                next_prompt = gemini_translate(next_prompt_en, \"en\", user_lang_code)\n",
        "                bot_response_user_lang = f\"{welcome_message}\\n\\n{next_prompt}\"\n",
        "\n",
        "                # Add to chat history\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"parts\": [{\"text\": f\"User selected language: {selected_language}\"}]\n",
        "                })\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"model\",\n",
        "                    \"parts\": [{\"text\": bot_response_en}]\n",
        "                })\n",
        "            else:\n",
        "                available_languages = \", \".join(sorted(LANG_CODES.keys()))\n",
        "                error_message_en = f\"Sorry, '{message}' is not a supported language. Please select from: {available_languages}\"\n",
        "                bot_response_en = error_message_en\n",
        "                # Don't translate error messages about language selection\n",
        "                bot_response_user_lang = error_message_en\n",
        "\n",
        "        elif current_stage == CHAT_STAGE_ASK_SYMPTOMS:\n",
        "            if not user_lang_code:\n",
        "                bot_response_en = \"Error: Language not set. Please start over.\"\n",
        "                bot_response_user_lang = bot_response_en\n",
        "                state = initialize_chat_state()\n",
        "            elif not message.strip():\n",
        "                bot_response_en = \"Please describe your symptoms so I can assist you.\"\n",
        "                bot_response_user_lang = gemini_translate(bot_response_en, \"en\", user_lang_code)\n",
        "            else:\n",
        "                state[\"symptoms_user_lang\"] = message.strip()\n",
        "                state[\"symptoms_en\"] = user_message_en\n",
        "                state[\"stage\"] = CHAT_STAGE_ASK_ALLERGIES\n",
        "\n",
        "                bot_response_en = \"Thank you for sharing your symptoms. Do you have any known allergies? If none, please say 'None'.\"\n",
        "                bot_response_user_lang = gemini_translate(bot_response_en, \"en\", user_lang_code)\n",
        "\n",
        "                # Add to chat history\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"parts\": [{\"text\": f\"Symptoms: {user_message_en}\"}]\n",
        "                })\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"model\",\n",
        "                    \"parts\": [{\"text\": bot_response_en}]\n",
        "                })\n",
        "\n",
        "        elif current_stage == CHAT_STAGE_ASK_ALLERGIES:\n",
        "            if not user_lang_code:\n",
        "                bot_response_en = \"Error: Language not set. Please start over.\"\n",
        "                bot_response_user_lang = bot_response_en\n",
        "                state = initialize_chat_state()\n",
        "            else:\n",
        "                state[\"allergies_user_lang\"] = message.strip()\n",
        "                state[\"allergies_en\"] = user_message_en\n",
        "                state[\"stage\"] = CHAT_STAGE_GENERATE_RESPONSE\n",
        "\n",
        "                # Add to chat history\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"user\",\n",
        "                    \"parts\": [{\"text\": f\"Allergies: {user_message_en}\"}]\n",
        "                })\n",
        "\n",
        "                # Show a processing message in the user's language while generating the response\n",
        "                processing_message_en = \"Thank you. I'm analyzing your symptoms and allergies to generate a diagnosis and drug concept. This may take a moment...\"\n",
        "                processing_message = gemini_translate(processing_message_en, \"en\", user_lang_code)\n",
        "\n",
        "                # Update history with processing message\n",
        "                if history and len(history) > 0:\n",
        "                    if isinstance(history[-1], list) and len(history[-1]) >= 2:\n",
        "                        history[-1][1] = processing_message\n",
        "                    else:\n",
        "                        history.append([message, processing_message])\n",
        "                else:\n",
        "                    history = [[message, processing_message]]\n",
        "\n",
        "                # Generate diagnosis and drug concept\n",
        "                symptoms = state[\"symptoms_en\"]\n",
        "                allergies = state[\"allergies_en\"]\n",
        "\n",
        "                prompt = f\"\"\"Based on the following symptoms and allergies, provide:\n",
        "                1. A potential diagnosis\n",
        "                2. A hypothetical new drug concept that could treat this condition\n",
        "                3. Hypothetical dosage instructions\n",
        "                4. Safety considerations related to the patient's allergies\n",
        "\n",
        "                Symptoms: {symptoms}\n",
        "                Allergies: {allergies}\n",
        "\n",
        "                Format your response with these exact headings:\n",
        "                Diagnosis:\n",
        "                Proposed New Drug:\n",
        "                Hypothetical Dosage/Instructions:\n",
        "                Allergy/Safety Note:\n",
        "                \"\"\"\n",
        "\n",
        "                diagnosis_response = get_gemini_response(prompt)\n",
        "                state[\"drug_concept_full_en\"] = diagnosis_response\n",
        "                state[\"stage\"] = CHAT_STAGE_GENERAL_QNA\n",
        "\n",
        "                bot_response_en = diagnosis_response\n",
        "                bot_response_user_lang = gemini_translate(diagnosis_response, \"en\", user_lang_code)\n",
        "\n",
        "                # Add to chat history\n",
        "                state[\"gemini_chat_history_manual\"].append({\n",
        "                    \"role\": \"model\",\n",
        "                    \"parts\": [{\"text\": bot_response_en}]\n",
        "                })\n",
        "\n",
        "                # Update summaries\n",
        "                diagnosis_match = re.search(r\"Diagnosis:(.*?)(?:Proposed New Drug:|Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                          diagnosis_response, re.DOTALL | re.IGNORECASE)\n",
        "                drug_match = re.search(r\"Proposed New Drug:(.*?)(?:Hypothetical Dosage/Instructions:|Allergy/Safety Note:|$)\",\n",
        "                                      diagnosis_response, re.DOTALL | re.IGNORECASE)\n",
        "                dosage_match = re.search(r\"Hypothetical Dosage/Instructions:(.*?)(?:Allergy/Safety Note:|$)\",\n",
        "                                        diagnosis_response, re.DOTALL | re.IGNORECASE)\n",
        "                safety_match = re.search(r\"Allergy/Safety Note:(.*)\",\n",
        "                                        diagnosis_response, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "                diagnosis = diagnosis_match.group(1).strip() if diagnosis_match else \"Not found\"\n",
        "                drug_concept = drug_match.group(1).strip() if drug_match else \"Not found\"\n",
        "                dosage = dosage_match.group(1).strip() if dosage_match else \"Not found\"\n",
        "                safety = safety_match.group(1).strip() if safety_match else \"Not found\"\n",
        "\n",
        "                # Create simplified bullet point summaries for better readability\n",
        "                diagnosis_simplified_prompt = \"Simplify this medical diagnosis into 2-3 short bullet points: \" + diagnosis\n",
        "                drug_simplified_prompt = \"Simplify this drug concept into 2-3 short bullet points about what it is and how it works: \" + drug_concept\n",
        "                dosage_simplified_prompt = \"Simplify this dosage information into 2-3 short bullet points about dosage amount, frequency, and how to take it: \" + dosage\n",
        "                safety_simplified_prompt = \"Simplify this safety information into 2-3 short bullet points about allergies and side effects: \" + safety\n",
        "\n",
        "                diagnosis_simplified = get_gemini_response(diagnosis_simplified_prompt)\n",
        "                drug_concept_simplified = get_gemini_response(drug_simplified_prompt)\n",
        "                dosage_simplified = get_gemini_response(dosage_simplified_prompt)\n",
        "                safety_simplified = get_gemini_response(safety_simplified_prompt)\n",
        "\n",
        "                # Create English summary with simplified text\n",
        "                english_summary = f\"*Symptoms:* {symptoms}\\n\\n\"\n",
        "                english_summary += f\"*Allergies:* {allergies}\\n\\n\"\n",
        "                english_summary += f\"*Diagnosis:* {diagnosis_simplified}\\n\\n\"\n",
        "                english_summary += f\"*Medicine:* {drug_concept_simplified}\\n\\n\"\n",
        "                english_summary += f\"*Dosage:* {dosage_simplified}\\n\\n\"\n",
        "                english_summary += f\"*Safety Notes:* {safety_simplified}\\n\\n\"\n",
        "\n",
        "                # Translate the simplified text to user's language\n",
        "                symptoms_title = gemini_translate(\"Symptoms\", \"en\", user_lang_code)\n",
        "                allergies_title = gemini_translate(\"Allergies\", \"en\", user_lang_code)\n",
        "                diagnosis_title = gemini_translate(\"Diagnosis\", \"en\", user_lang_code)\n",
        "                drug_title = gemini_translate(\"Medicine\", \"en\", user_lang_code)\n",
        "                dosage_title = gemini_translate(\"Dosage\", \"en\", user_lang_code)\n",
        "                safety_title = gemini_translate(\"Safety Notes\", \"en\", user_lang_code)\n",
        "\n",
        "                translated_diagnosis = gemini_translate(diagnosis_simplified, \"en\", user_lang_code)\n",
        "                translated_drug = gemini_translate(drug_concept_simplified, \"en\", user_lang_code)\n",
        "                translated_dosage = gemini_translate(dosage_simplified, \"en\", user_lang_code)\n",
        "                translated_safety = gemini_translate(safety_simplified, \"en\", user_lang_code)\n",
        "\n",
        "                # Only show the translated summary in the user's language with clear formatting\n",
        "                translated_summary = f\"### {symptoms_title}:\\n{state['symptoms_user_lang']}\\n\\n\"\n",
        "                translated_summary += f\"### {allergies_title}:\\n{state['allergies_user_lang']}\\n\\n\"\n",
        "                translated_summary += f\"### {diagnosis_title}:\\n{translated_diagnosis}\\n\\n\"\n",
        "                translated_summary += f\"### {drug_title}:\\n{translated_drug}\\n\\n\"\n",
        "                translated_summary += f\"### {dosage_title}:\\n{translated_dosage}\\n\\n\"\n",
        "                translated_summary += f\"### {safety_title}:\\n{translated_safety}\\n\\n\"\n",
        "\n",
        "        elif current_stage == CHAT_STAGE_GENERAL_QNA:\n",
        "            # Add user question to history\n",
        "            state[\"gemini_chat_history_manual\"].append({\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [{\"text\": user_message_en}]\n",
        "            })\n",
        "\n",
        "            # Show a processing message in the user's language while generating the response\n",
        "            processing_message_en = \"I'm thinking about your question...\"\n",
        "            processing_message = gemini_translate(processing_message_en, \"en\", user_lang_code)\n",
        "\n",
        "            # Update history with processing message\n",
        "            if history and len(history) > 0:\n",
        "                if isinstance(history[-1], list) and len(history[-1]) >= 2:\n",
        "                    history[-1][1] = processing_message\n",
        "                else:\n",
        "                    history.append([message, processing_message])\n",
        "            else:\n",
        "                history = [[message, processing_message]]\n",
        "\n",
        "            # Generate response to follow-up question\n",
        "            context = f\"\"\"\n",
        "            Previous symptoms: {state.get('symptoms_en', 'None')}\n",
        "            Previous allergies: {state.get('allergies_en', 'None')}\n",
        "            Previous diagnosis and drug concept: {state.get('drug_concept_full_en', 'None')}\n",
        "\n",
        "            User question: {user_message_en}\n",
        "\n",
        "            Respond in a clear, concise way that would be easy to translate to another language.\n",
        "            \"\"\"\n",
        "\n",
        "            qna_response = get_gemini_response(context)\n",
        "\n",
        "            bot_response_en = qna_response\n",
        "            bot_response_user_lang = gemini_translate(qna_response, \"en\", user_lang_code)\n",
        "\n",
        "            # Add to chat history\n",
        "            state[\"gemini_chat_history_manual\"].append({\n",
        "                \"role\": \"model\",\n",
        "                \"parts\": [{\"text\": bot_response_en}]\n",
        "            })\n",
        "\n",
        "        # Always use the translated response in the user's language for the chat interface\n",
        "        # This ensures all bot responses appear in the user's chosen language\n",
        "        if history and len(history) > 0:\n",
        "            if isinstance(history[-1], list) and len(history[-1]) >= 2:\n",
        "                history[-1][1] = bot_response_user_lang\n",
        "            else:\n",
        "                history.append([message, bot_response_user_lang])\n",
        "        else:\n",
        "            history = [[message, bot_response_user_lang]]\n",
        "\n",
        "        return history, english_summary, translated_summary, state\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in chat processing: {e}\")\n",
        "        error_message = f\"An error occurred: {e}. Please try again or restart the conversation.\"\n",
        "\n",
        "        # Update history with error message\n",
        "        if history and len(history) > 0:\n",
        "            if isinstance(history[-1], list) and len(history[-1]) >= 2:\n",
        "                history[-1][1] = error_message\n",
        "            else:\n",
        "                history.append([message, error_message])\n",
        "        else:\n",
        "            history = [[message, error_message]]\n",
        "\n",
        "        return history, f\"Error: {error_message}\", f\"Error: {error_message}\", initialize_chat_state()\n",
        "\n",
        "# --- Gradio Interface ---\n",
        "def create_interface():\n",
        "    with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"indigo\", secondary_hue=\"cyan\"),\n",
        "                  css=\"\"\"\n",
        "                  .gradio-container {\n",
        "                      background: linear-gradient(135deg, #0f0c29, #302b63, #24243e);\n",
        "                      color: white;\n",
        "                      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "                  }\n",
        "                  .chatbot-container {\n",
        "                      border-radius: 20px;\n",
        "                      box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);\n",
        "                      backdrop-filter: blur(8px);\n",
        "                      border: 1px solid rgba(255, 255, 255, 0.18);\n",
        "                      padding: 20px;\n",
        "                      background: rgba(255, 255, 255, 0.05);\n",
        "                  }\n",
        "                  .summary-container {\n",
        "                      background: rgba(255, 255, 255, 0.05);\n",
        "                      border-radius: 20px;\n",
        "                      padding: 20px;\n",
        "                      box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);\n",
        "                      backdrop-filter: blur(8px);\n",
        "                      border: 1px solid rgba(255, 255, 255, 0.18);\n",
        "                  }\n",
        "                  .button-row {\n",
        "                      display: flex;\n",
        "                      justify-content: space-between;\n",
        "                      margin-top: 15px;\n",
        "                  }\n",
        "                  .chat-header {\n",
        "                      text-align: center;\n",
        "                      margin-bottom: 30px;\n",
        "                      animation: glow 2s ease-in-out infinite alternate;\n",
        "                  }\n",
        "                  @keyframes glow {\n",
        "                      from {\n",
        "                          text-shadow: 0 0 10px rgba(66, 153, 225, 0.5), 0 0 20px rgba(66, 153, 225, 0.3);\n",
        "                      }\n",
        "                      to {\n",
        "                          text-shadow: 0 0 20px rgba(66, 153, 225, 0.8), 0 0 30px rgba(66, 153, 225, 0.5);\n",
        "                      }\n",
        "                  }\n",
        "                  .send-btn {\n",
        "                      background: linear-gradient(90deg, #4299e1, #667eea);\n",
        "                      border: none;\n",
        "                      border-radius: 50px;\n",
        "                      transition: all 0.3s ease;\n",
        "                  }\n",
        "                  .send-btn:hover {\n",
        "                      transform: translateY(-2px);\n",
        "                      box-shadow: 0 5px 15px rgba(66, 153, 225, 0.4);\n",
        "                  }\n",
        "                  .download-btn {\n",
        "                      background: linear-gradient(90deg, #00c6fb, #005bea);\n",
        "                      border: none;\n",
        "                      border-radius: 50px;\n",
        "                      transition: all 0.3s ease;\n",
        "                  }\n",
        "                  .download-btn:hover {\n",
        "                      transform: translateY(-2px);\n",
        "                      box-shadow: 0 5px 15px rgba(0, 198, 251, 0.4);\n",
        "                  }\n",
        "                  .clear-btn {\n",
        "                      background: linear-gradient(90deg, #ff9a9e, #fad0c4);\n",
        "                      border: none;\n",
        "                      border-radius: 50px;\n",
        "                      transition: all 0.3s ease;\n",
        "                  }\n",
        "                  .clear-btn:hover {\n",
        "                      transform: translateY(-2px);\n",
        "                      box-shadow: 0 5px 15px rgba(255, 154, 158, 0.4);\n",
        "                  }\n",
        "                  .chatbot-message {\n",
        "                      border-radius: 18px !important;\n",
        "                      padding: 12px 18px !important;\n",
        "                      margin-bottom: 10px !important;\n",
        "                  }\n",
        "                  .user-message {\n",
        "                      background: linear-gradient(90deg, #4299e1, #667eea) !important;\n",
        "                      color: white !important;\n",
        "                  }\n",
        "                  .bot-message {\n",
        "                      background: rgba(255, 255, 255, 0.1) !important;\n",
        "                      backdrop-filter: blur(5px) !important;\n",
        "                      border: 1px solid rgba(255, 255, 255, 0.1) !important;\n",
        "                  }\n",
        "                  .summary-title {\n",
        "                      font-size: 1.5em;\n",
        "                      font-weight: 600;\n",
        "                      margin-bottom: 15px;\n",
        "                      color: #4cc9f0;\n",
        "                      text-shadow: 0 0 10px rgba(76, 201, 240, 0.3);\n",
        "                  }\n",
        "                  .textbox-container {\n",
        "                      margin-top: 15px;\n",
        "                      border-radius: 50px;\n",
        "                      overflow: hidden;\n",
        "                      box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);\n",
        "                  }\n",
        "                  \"\"\") as demo:\n",
        "\n",
        "        # Header with animated glow effect\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"chat-header\">\n",
        "            <h1 style=\"color: #4cc9f0; font-size: 3em; font-weight: 700; letter-spacing: 2px;\">\n",
        "                🧬 PharmaGPT 🧬\n",
        "            </h1>\n",
        "            <h3 style=\"color: #f72585; margin-top: -10px; font-style: italic; letter-spacing: 1px;\">\n",
        "                Next-Gen Medical Assistant & Drug Concept Generator\n",
        "            </h3>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Language selector with visual indicators\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "            <p style=\"color: #4cc9f0; font-size: 1.2em;\">\n",
        "                Start by typing your preferred language below\n",
        "            </p>\n",
        "            <div style=\"display: flex; justify-content: center; gap: 10px; flex-wrap: wrap; margin-top: 10px;\">\n",
        "                <span style=\"background: rgba(255,255,255,0.1); padding: 5px 10px; border-radius: 20px; font-size: 0.9em;\">English</span>\n",
        "                <span style=\"background: rgba(255,255,255,0.1); padding: 5px 10px; border-radius: 20px; font-size: 0.9em;\">Hindi</span>\n",
        "                <span style=\"background: rgba(255,255,255,0.1); padding: 5px 10px; border-radius: 20px; font-size: 0.9em;\">Spanish</span>\n",
        "                <span style=\"background: rgba(255,255,255,0.1); padding: 5px 10px; border-radius: 20px; font-size: 0.9em;\">Kannada</span>\n",
        "                <span style=\"background: rgba(255,255,255,0.1); padding: 5px 10px; border-radius: 20px; font-size: 0.9em;\">+16 more</span>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Chat state\n",
        "        chat_state = gr.State(initialize_chat_state())\n",
        "\n",
        "        with gr.Row():\n",
        "            # Main chat area\n",
        "            with gr.Column(scale=3, elem_classes=\"chatbot-container\"):\n",
        "                chatbot = gr.Chatbot(\n",
        "                    height=500,\n",
        "                    bubble_full_width=False,\n",
        "                    show_label=False,\n",
        "                    elem_id=\"pharma-chat\",\n",
        "                    elem_classes=\"chatbot-message\"\n",
        "                )\n",
        "\n",
        "                with gr.Row(elem_classes=\"textbox-container\"):\n",
        "                    txt = gr.Textbox(\n",
        "                        placeholder=\"Type your message here...\",\n",
        "                        container=False,\n",
        "                        scale=8,\n",
        "                        show_label=False\n",
        "                    )\n",
        "                    send_btn = gr.Button(\"Send\", variant=\"primary\", scale=1, elem_classes=\"send-btn\")\n",
        "\n",
        "            # Side panel - Only show translated summary\n",
        "            with gr.Column(scale=2, elem_classes=\"summary-container\"):\n",
        "                gr.HTML('<div class=\"summary-title\">📊 Your Medical Report</div>')\n",
        "\n",
        "                # Hide the English summary and only show the translated one\n",
        "                english_summary = gr.Markdown(\n",
        "                    value=\"\",\n",
        "                    label=\"English Summary\",\n",
        "                    visible=False  # Hide this component\n",
        "                )\n",
        "\n",
        "                translated_summary = gr.Markdown(\n",
        "                    value=\"Your report will appear here after diagnosis in your chosen language.\",\n",
        "                    label=\"\"  # Remove label as it's redundant\n",
        "                )\n",
        "\n",
        "                with gr.Row(elem_classes=\"button-row\"):\n",
        "                    download_btn = gr.Button(\"📥 Download PDF Report\", variant=\"secondary\", elem_classes=\"download-btn\")\n",
        "                    clear_btn = gr.Button(\"🔄 New Consultation\", variant=\"stop\", elem_classes=\"clear-btn\")\n",
        "\n",
        "                pdf_output = gr.File(label=\"Download Report\", visible=False)\n",
        "\n",
        "        # Disclaimer with improved styling\n",
        "        with gr.Accordion(\"⚠ Important Medical Disclaimer\", open=False):\n",
        "            gr.HTML(\"\"\"\n",
        "            <div style=\"color: #f72585; font-size: 0.9em; padding: 15px; background: rgba(247, 37, 133, 0.1); border-radius: 15px;\">\n",
        "                <p style=\"font-weight: 600; font-size: 1.1em;\">This application is for informational and conceptual purposes only.</p>\n",
        "                <ul style=\"list-style-type: none; padding-left: 10px;\">\n",
        "                    <li style=\"margin-bottom: 10px; display: flex; align-items: flex-start;\">\n",
        "                        <span style=\"margin-right: 10px; font-size: 1.2em;\">⚕</span>\n",
        "                        <span><b>AI-Generated Diagnosis:</b> The diagnosis provided is AI-generated and may not be accurate.\n",
        "                        <strong>Always consult a qualified medical professional for any health concerns.</strong></span>\n",
        "                    </li>\n",
        "                    <li style=\"margin-bottom: 10px; display: flex; align-items: flex-start;\">\n",
        "                        <span style=\"margin-right: 10px; font-size: 1.2em;\">🧪</span>\n",
        "                        <span><b>Hypothetical Drug Concepts:</b> The drug compounds suggested are NEW, HYPOTHETICAL CONCEPTS\n",
        "                        generated by AI. <strong>They are not real, tested, safe, or approved medications.</strong></span>\n",
        "                    </li>\n",
        "                    <li style=\"margin-bottom: 10px; display: flex; align-items: flex-start;\">\n",
        "                        <span style=\"margin-right: 10px; font-size: 1.2em;\">⚠</span>\n",
        "                        <span><b>Safety Notes:</b> Allergy and side effect notes are theoretical AI assessments.\n",
        "                        <strong>They are not a substitute for professional medical advice.</strong></span>\n",
        "                    </li>\n",
        "                </ul>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "        # Event handlers\n",
        "        send_btn.click(\n",
        "            fn=process_chat,\n",
        "            inputs=[txt, chatbot, chat_state],\n",
        "            outputs=[chatbot, english_summary, translated_summary, chat_state]\n",
        "        ).then(\n",
        "            fn=lambda: \"\",\n",
        "            inputs=None,\n",
        "            outputs=txt\n",
        "        )\n",
        "\n",
        "        txt.submit(\n",
        "            fn=process_chat,\n",
        "            inputs=[txt, chatbot, chat_state],\n",
        "            outputs=[chatbot, english_summary, translated_summary, chat_state]\n",
        "        ).then(\n",
        "            fn=lambda: \"\",\n",
        "            inputs=None,\n",
        "            outputs=txt\n",
        "        )\n",
        "\n",
        "        if IN_COLAB:\n",
        "            # For Colab, use a direct download approach\n",
        "            download_btn.click(\n",
        "                fn=generate_pdf_report,\n",
        "                inputs=[chat_state],\n",
        "                outputs=[pdf_output]\n",
        "            ).then(\n",
        "                fn=download_pdf_in_colab,\n",
        "                inputs=[pdf_output],\n",
        "                outputs=[gr.Textbox(visible=False)]\n",
        "            )\n",
        "        else:\n",
        "            # For regular environments\n",
        "            download_btn.click(\n",
        "                fn=generate_pdf_report,\n",
        "                inputs=[chat_state],\n",
        "                outputs=[pdf_output]\n",
        "            )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=lambda: ([], \"\",\n",
        "                       \"Your report will appear here after diagnosis in your chosen language.\",\n",
        "                       initialize_chat_state()),\n",
        "            inputs=None,\n",
        "            outputs=[chatbot, english_summary, translated_summary, chat_state]\n",
        "        )\n",
        "\n",
        "        # Footer with animated effect\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-top: 30px; padding: 15px; background: rgba(255,255,255,0.05);\n",
        "                    border-radius: 15px; backdrop-filter: blur(5px);\">\n",
        "            <p style=\"color: #4cc9f0; font-size: 0.9em; margin-bottom: 5px;\">\n",
        "                Powered by Google Gemini AI\n",
        "            </p>\n",
        "            <p style=\"color: #aaa; font-size: 0.8em;\">\n",
        "                Created for educational and conceptual purposes only\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_interface()\n",
        "    if IN_COLAB:\n",
        "        # In Colab, always use share=True to get a public URL\n",
        "        demo.launch(share=True, debug=True)\n",
        "    else:\n",
        "        # For local development\n",
        "        demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2VCae5jS-jO",
        "outputId": "baacd636-8453-44a6-bf81-2f5f20282c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running in Google Colab environment\n",
            "Gemini API client initialized with model: gemini-1.5-flash-latest\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-bd077cceba4b>:745: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "<ipython-input-7-bd077cceba4b>:745: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fe9584f3d858d22b6b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://fe9584f3d858d22b6b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1594.61ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.60ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1264.97ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.34ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 607.76ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 609.98ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.50ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.58ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.72ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.05ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.00ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.35ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.13ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1318.49ms\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        }
      ]
    }
  ]
}